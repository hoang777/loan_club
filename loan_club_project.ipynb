{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression, SelectKBest, SelectPercentile\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import validation_curve, cross_val_score, learning_curve, train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Challenge\n",
    "## Objective: improve performance\n",
    "### Benchmark: https://triamus.github.io/project/lending-club-loan-data-in-r/#loan-amount-and-income\n",
    "\n",
    "Some steps with preprocessing data was skipped, due to time constraint. The project is mainly supposed to show the improvement of the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First Steps\n",
    "\n",
    "<li> Load Data \n",
    "<li> Use algorithm/ techinques to intelligently remove rest of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load(\"data.npz\",allow_pickle=True)\n",
    "values = dat[\"arr_0\"]\n",
    "header = dat[\"arr_1\"]\n",
    "dt = pd.DataFrame(values,columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection \n",
    "\n",
    "Problem of using all variables? Overfitting. Instead of handpicking variables, I'll try to use an algorithm to pick \"right\" features.\n",
    "<br>\n",
    "Options:\n",
    "<li> Forward Selection\n",
    "<li> Backward Selection\n",
    "<li> Mutual Information Classification\n",
    "<br>\n",
    "Due to computing capacity and a sizable dataset, I'll use Mutual Information Classification to pick up first 30 and then Forward Selection to get 10 \"best\" features. In that way I will skip features that are correlated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given variables $X$ and $Y$, Mutual information (MI) measures the information that $X$ and $Y$ share. We will first calculate MI for each variable and pick up \"top\" 40 features.\n",
    "\n",
    "NOTE: On my computer this section run for over 2 hours. I uploaded parameters that can be loaded directly. To save time proceed to next section to load parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(\"loan_status\", axis=1)\n",
    "y = dt[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If paramteters exist, load. Else, mutual information.\n",
    "mutual_info = mutual_info_classif(X, y)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mi_series = pd.Series(mutual_info)\n",
    "mi_series.index = X.columns\n",
    "mi_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_series.sort_values(ascending=False).plot.bar(figsize=(20,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If saved parameters exist, load. Else, run function for best features \n",
    "k_best_features = SelectKBest(mutual_info_classif, k=30).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selected top 30 features: {}'.format(x_train.columns[k_best_features.get_support()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mutual_information = x_train.columns[k_best_features.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[columns_mutual_information]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Left Features Use Forward Selection to pick up 10 variables\n",
    "\n",
    "I will use a Forward Looking Algorithm using a simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "\n",
    "X_forward = X_train[columns_mutual_information]\n",
    "X_forward_test = X_test[columns_mutual_information]\n",
    "\n",
    "\n",
    "\n",
    "sfs1 = SFS(logisticRegr,\n",
    "           k_features=12,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='recall',\n",
    "           cv=5,\n",
    "           n_jobs=-1)\n",
    "\n",
    "mu_col = sfs1.fit(X_forward_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_forward = list(sfs1.subsets_[12]['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[columns_forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Try with new variable set\n",
    "First, I will use the new parameters with a simple logisti regression, then I will experiement around with SVM. Finally, the plan is to set up a small neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.fit(X_train_scale, y_train)\n",
    "predictions = logisticRegr.predict(X_test_scale)\n",
    "\n",
    "\n",
    "print(\"F1: \" + str(metrics.f1_score(y_test, predictions)))\n",
    "print(\"Accuracy: \" + str(metrics.accuracy_score(y_test, predictions)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predictions)))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(X_train_scale)\n",
    "\n",
    "print(\"F1: \" + str(metrics.f1_score(y_train, predictions)))\n",
    "print(\"Accuracy: \" + str(metrics.accuracy_score(y_train, predictions)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_train, predictions)))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_train, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(penalty='l2', random_state = 0, C=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.fit(X_train_scale, y_train)\n",
    "predictions = logisticRegr.predict(X_test_scale)\n",
    "\n",
    "\n",
    "print(\"F1: \" + str(metrics.f1_score(y_test, predictions)))\n",
    "print(\"Accuracy: \" + str(metrics.accuracy_score(y_test_scale, predictions)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_scale, predictions)))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_scale, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using CV\n",
    "classifier = LogisticRegression()\n",
    "f1 = cross_val_score(classifier, X_train_scale, y_train, cv=5, scoring='f1', verbose=1)\n",
    "recall = cross_val_score(classifier, X_train_scale, y_train, cv=5, scoring='recall', verbose=1)\n",
    "accuracy = cross_val_score(classifier, X_train_scale, y_train, cv=5, scoring='accuracy', verbose=1)\n",
    "scores = cross_val_score(classifier, X_train_scale, y_train, cv=5, scoring='precision', verbose=1)\n",
    "\n",
    "print('F1' , np.mean(f1))\n",
    "print('Accuracy' , np.mean(scores))\n",
    "print('Precision' , np.mean(scores))\n",
    "print('Recall' , np.mean(recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = np.arange(0.2, 1, 0.1)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = LogisticRegression(),\n",
    "                                                        X = X_train_scale,\n",
    "                                                        y = y_train,\n",
    "                                                        train_sizes = train_size, \n",
    "                                                        cv = 5,\n",
    "                                                        scoring = 'roc_auc',\n",
    "                                                        n_jobs= -1)\n",
    "\n",
    "\n",
    "print('Training scores:\\n\\n', train_scores)\n",
    "print('\\n', '-' * 70) # separator to make the output easy to read\n",
    "print('\\nValidation scores:\\n\\n', test_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "test_scores_mean = test_scores.mean(axis = 1)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training')\n",
    "plt.plot(train_sizes, test_scores_mean, label = 'Test')\n",
    "plt.ylabel('roc_auc', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0.98,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = LogisticRegression(),\n",
    "                                                        X = X_train_scale,\n",
    "                                                        y = y_train,\n",
    "                                                        train_sizes = train_size, \n",
    "                                                        cv = 5,\n",
    "                                                        scoring = 'f1',\n",
    "                                                        n_jobs= -1)\n",
    "\n",
    "\n",
    "print('Training scores:\\n\\n', train_scores)\n",
    "print('\\n', '-' * 70) # separator to make the output easy to read\n",
    "print('\\nValidation scores:\\n\\n', test_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "test_scores_mean = test_scores.mean(axis = 1)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training')\n",
    "plt.plot(train_sizes, test_scores_mean, label = 'Test')\n",
    "plt.ylabel('f1', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0.98,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(np.power(10.0, np.arange(-10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_param_range = [0.05, 0.1, 1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(estimator=lr,\n",
    "                                             X=X_train_scale,\n",
    "                                             y=y_train,\n",
    "                                             param_name='C',\n",
    "                                             param_range=C_param_range,\n",
    "                                             cv=5,\n",
    "                                             scoring=\"roc_auc\",\n",
    "                                             n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores,axis=1)\n",
    "test_mean = np.mean(test_scores,axis=1)\n",
    "test_std = np.std(test_scores,axis=1)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(C_param_range, train_mean, color='blue', label='Training')\n",
    "plt.plot(C_param_range, test_mean, color='green', label='Test')\n",
    "plt.ylabel('ROC', fontsize = 14)\n",
    "plt.xlabel('C Parameter', fontsize = 14)\n",
    "plt.title('Regularization', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0.8,1)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Conclusion\n",
    "\n",
    "Tasks done:\n",
    "1. Picked variables on Mutual Information\n",
    "2. Picked variables left with forward search algorithm\n",
    "3. Logistic Regression model\n",
    "4. Logistic Regression with regularization (validation curve)\n",
    "\n",
    "Conclusion:\n",
    "1. Picking up right variables increased accuracy, precision , and recall\n",
    "2. Learning Curve shows convergence\n",
    "3. Validation curve shows no variance bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider\n",
    "\n",
    "n_estimators = number of trees in the foreset <br>\n",
    "max_features = max number of features considered for splitting a node<br>\n",
    "max_depth = max number of levels in each decision tree<br>\n",
    "min_samples_split = min number of data points placed in a node before the node is split<br>\n",
    "min_samples_leaf = min number of data points allowed in a leaf node<br>\n",
    "bootstrap = method for sampling data points (with or without replacement)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Randomized Grid Search to find \"better\" parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_col = x_train.columns[k_best_features.get_support()]\n",
    "svm_col = svm_col[0:20]\n",
    "X_scale = X[svm_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, Y, test_size = 0.80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [0.05, 0.1, 0.15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.001, 0.0001,0.01, 0.004]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, \n",
    "                               n_jobs=-1, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators = 300,\n",
    "                           max_features = 'log2',\n",
    "                           max_depth = 50,\n",
    "                           min_samples_split = 0.05,\n",
    "                           min_samples_leaf = 0.001,\n",
    "                           bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 32.98019338, 154.3762579 , 139.85794648,  94.98654048,\n",
       "         72.96919203,  56.20011298, 216.4041357 , 104.87715308,\n",
       "         99.39741524,  73.83505694,  36.36487738, 254.06643764,\n",
       "        100.53091272, 154.51166153,  78.19716295, 155.27521729,\n",
       "         48.31709607,  62.7357587 , 156.07490365, 220.57057556,\n",
       "        167.23535601, 217.34587963,  40.88605769, 181.83446916,\n",
       "         61.11850007,  76.86172978,  68.72640077, 130.39366992,\n",
       "         31.23832329, 162.2705512 , 176.71290676, 186.76975679,\n",
       "         73.2292974 ,  55.45762626,  51.06478945, 203.36302988,\n",
       "         81.7672863 ,  99.30898174,  64.16728671, 165.95502265,\n",
       "         36.24921012,  35.53760107,  96.52234689, 172.21600668,\n",
       "        247.98088392, 126.63427003, 150.3806754 , 167.28696926,\n",
       "        127.60603174, 204.5676566 , 135.22532002, 119.99040858,\n",
       "        141.82827385, 116.70062677, 201.8100601 , 110.29096691,\n",
       "         37.30335959, 124.67436997, 294.52969305, 154.66346407,\n",
       "         32.91133952, 150.45100005, 217.03990706, 295.08591636,\n",
       "        117.35664471,  24.99617251, 181.3336997 , 182.1999797 ,\n",
       "        111.1798261 , 203.03889831, 153.26480254,  41.18465169,\n",
       "         79.87368925,  81.05938013, 161.96883941, 211.64975532,\n",
       "         35.85174171, 154.70635494, 103.72950172,  56.14506133,\n",
       "         28.95329944, 106.49702334, 131.85012563,  31.50306137,\n",
       "        160.00971794, 117.00461062,  54.9051702 , 126.61992701,\n",
       "        141.82194304, 137.35663621, 199.6426754 , 151.57189496,\n",
       "         46.39143674, 185.68226965,  46.88975215, 226.49280254,\n",
       "        133.29057598, 261.7528526 , 121.26152762, 144.85950096]),\n",
       " 'std_fit_time': array([ 0.4004431 ,  7.57486624,  2.53952919,  4.16960783,  2.79440854,\n",
       "         0.92171898,  2.84778813,  0.91292947,  1.43090623,  2.04991063,\n",
       "         2.10342327,  0.80460002,  8.06072775,  0.63574539,  0.31410474,\n",
       "         1.42980451,  1.96176949,  3.21395663,  0.08097573, 15.02389396,\n",
       "         4.25389392,  1.81922434,  1.13925247,  1.47161454,  3.13629966,\n",
       "         0.85991883,  5.60860671,  6.99173363,  0.73364593,  0.83002346,\n",
       "         3.83946936,  8.10408958,  2.97391081,  3.79664284,  5.5816879 ,\n",
       "         6.0347478 ,  2.40819667,  2.79508166,  2.96277322,  1.49093317,\n",
       "         1.76358001,  1.44290858,  3.01072124,  4.03939458, 13.20490287,\n",
       "        12.47350773,  3.08199892,  0.4621421 ,  7.45951646, 12.58149906,\n",
       "        12.4800012 ,  0.88420038,  0.9442524 ,  1.17876017,  2.1828499 ,\n",
       "         1.9382728 ,  1.04907896,  1.19294745,  2.65713393,  2.27382108,\n",
       "         0.75255486,  1.12247978,  1.31426341, 19.1874623 ,  5.08215671,\n",
       "         0.52880209,  0.36505877,  1.01185111,  1.54680132,  0.82826428,\n",
       "         2.07232593,  1.0368714 ,  0.81693707,  1.48118816,  2.36735582,\n",
       "         1.72749948,  0.22737109,  2.82423413,  0.45850798,  1.81399027,\n",
       "         0.23385533,  1.0932184 ,  0.98706043,  0.21778215,  0.84170528,\n",
       "         2.10556467,  0.14636539,  1.4747311 ,  1.67048645,  1.47529777,\n",
       "         2.26365974,  0.77753226,  1.11077268,  1.28293875,  0.14168492,\n",
       "         4.42852858, 11.55098662,  3.50988795,  6.61564179, 20.48897279]),\n",
       " 'mean_score_time': array([1.150189  , 6.91263636, 3.63977687, 3.84226378, 1.95717891,\n",
       "        1.55353371, 5.55777272, 2.50689856, 2.53997151, 2.72768005,\n",
       "        1.22844593, 6.36287268, 3.77725967, 5.14729842, 2.78422801,\n",
       "        5.20067811, 1.93385561, 2.0949742 , 4.11571376, 6.17586335,\n",
       "        5.51902692, 6.02339315, 1.26722741, 5.85960261, 1.37323872,\n",
       "        2.35807474, 1.61989935, 4.46309932, 1.06166395, 4.27294517,\n",
       "        6.4927361 , 5.68908294, 2.27247787, 3.0272963 , 1.49010396,\n",
       "        6.84136113, 2.30780689, 2.42647163, 1.70943197, 5.28897031,\n",
       "        1.57990758, 1.28900027, 2.96052575, 5.30829899, 4.99367746,\n",
       "        3.053219  , 4.0049816 , 3.84083835, 4.43169006, 7.5034709 ,\n",
       "        3.66270296, 2.58032107, 4.83851242, 2.9775823 , 4.96540229,\n",
       "        3.95057607, 1.20757707, 3.16133547, 6.76917235, 4.17305636,\n",
       "        1.10580842, 5.40653594, 6.93881257, 6.18486993, 3.55161858,\n",
       "        0.9486324 , 4.54030434, 4.36263235, 4.56361294, 5.08412401,\n",
       "        5.10207637, 1.03867133, 2.97104772, 2.89643248, 4.07863967,\n",
       "        5.43092299, 1.20412668, 4.12844427, 3.78356934, 1.27142366,\n",
       "        1.04408423, 3.02260868, 4.82841619, 1.10910606, 4.17331251,\n",
       "        3.56555597, 1.94962502, 3.19734168, 3.88150771, 3.2929937 ,\n",
       "        4.83467372, 3.64163605, 1.23318632, 4.58488743, 1.10081498,\n",
       "        7.01051172, 4.98880506, 6.33734401, 5.00189281, 3.04223871]),\n",
       " 'std_score_time': array([0.00956808, 0.32656243, 0.71545477, 1.14964949, 0.36203887,\n",
       "        0.19055803, 0.07466088, 0.15490414, 0.30805933, 0.23887912,\n",
       "        0.22304457, 0.10399454, 0.47310595, 0.30555833, 0.04772977,\n",
       "        0.0807705 , 0.05388271, 0.02826039, 0.01946266, 0.07388917,\n",
       "        0.54683686, 0.19304756, 0.06040493, 0.51934871, 0.07326422,\n",
       "        0.05754604, 0.15836004, 0.57234026, 0.04054971, 0.71659985,\n",
       "        0.40103672, 0.12910484, 0.13019726, 1.10402661, 0.19757732,\n",
       "        0.47345646, 0.06321898, 0.18519881, 0.29690951, 0.44178539,\n",
       "        0.25341596, 0.19598577, 0.06879733, 0.51683724, 0.1295966 ,\n",
       "        0.05860382, 0.0184495 , 0.05431846, 0.19111128, 0.94259981,\n",
       "        0.07251631, 0.04591747, 0.17590693, 0.16670943, 0.9312018 ,\n",
       "        0.27509988, 0.03096445, 0.10761257, 0.02563428, 0.43515785,\n",
       "        0.03259184, 0.34097188, 0.09002251, 0.0590178 , 0.01579885,\n",
       "        0.01203182, 0.08031964, 0.01763447, 0.01047218, 0.04538532,\n",
       "        0.03297855, 0.01054983, 0.04397464, 0.02834498, 0.0062286 ,\n",
       "        0.22946788, 0.02082103, 0.21911839, 0.04527445, 0.00379968,\n",
       "        0.01516099, 0.21992581, 0.02369252, 0.00790712, 0.04145554,\n",
       "        0.01749831, 0.01239614, 0.13771295, 0.00836702, 0.02233929,\n",
       "        0.04003231, 0.03504765, 0.07590273, 0.02757167, 0.0082828 ,\n",
       "        0.10065806, 0.13980187, 0.16833807, 0.71173148, 2.00090289]),\n",
       " 'param_n_estimators': masked_array(data=[100, 500, 300, 300, 100, 100, 500, 200, 200, 200, 100,\n",
       "                    500, 300, 500, 300, 500, 200, 200, 400, 500, 400, 500,\n",
       "                    100, 500, 100, 200, 100, 300, 100, 300, 400, 500, 200,\n",
       "                    200, 100, 500, 200, 200, 100, 400, 100, 100, 200, 400,\n",
       "                    400, 300, 400, 300, 400, 500, 300, 200, 400, 200, 300,\n",
       "                    300, 100, 300, 500, 300, 100, 400, 500, 500, 300, 100,\n",
       "                    400, 400, 500, 500, 500, 100, 300, 300, 400, 500, 100,\n",
       "                    400, 400, 100, 100, 300, 500, 100, 400, 300, 200, 300,\n",
       "                    400, 300, 400, 300, 100, 400, 100, 500, 300, 400, 300,\n",
       "                    200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[0.05, 0.15, 0.15, 0.15, 0.05, 0.15, 0.15, 0.05, 0.1,\n",
       "                    0.05, 0.1, 0.05, 0.05, 0.15, 0.15, 0.1, 0.15, 0.1, 0.1,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.05, 0.1, 0.05, 0.05,\n",
       "                    0.15, 0.1, 0.05, 0.1, 0.1, 0.15, 0.05, 0.05, 0.15, 0.1,\n",
       "                    0.05, 0.05, 0.05, 0.1, 0.15, 0.05, 0.05, 0.15, 0.15,\n",
       "                    0.05, 0.1, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.1, 0.15, 0.05, 0.1, 0.15, 0.1, 0.05, 0.05, 0.05,\n",
       "                    0.15, 0.05, 0.1, 0.15, 0.15, 0.1, 0.15, 0.1, 0.15,\n",
       "                    0.15, 0.1, 0.05, 0.15, 0.15, 0.05, 0.1, 0.15, 0.1,\n",
       "                    0.05, 0.1, 0.05, 0.15, 0.1, 0.15, 0.1, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.1, 0.15, 0.05, 0.05, 0.1, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[0.01, 0.001, 0.004, 0.001, 0.001, 0.004, 0.01, 0.01,\n",
       "                    0.001, 0.01, 0.004, 0.004, 0.01, 0.001, 0.01, 0.004,\n",
       "                    0.01, 0.004, 0.01, 0.001, 0.004, 0.001, 0.001, 0.001,\n",
       "                    0.004, 0.001, 0.004, 0.004, 0.001, 0.004, 0.004, 0.004,\n",
       "                    0.001, 0.01, 0.004, 0.004, 0.01, 0.001, 0.001, 0.004,\n",
       "                    0.01, 0.004, 0.001, 0.004, 0.004, 0.004, 0.004, 0.001,\n",
       "                    0.001, 0.01, 0.004, 0.004, 0.01, 0.004, 0.001, 0.01,\n",
       "                    0.001, 0.01, 0.004, 0.004, 0.001, 0.004, 0.004, 0.004,\n",
       "                    0.001, 0.004, 0.01, 0.001, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.001, 0.001, 0.004, 0.001, 0.004, 0.004, 0.001,\n",
       "                    0.004, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.004,\n",
       "                    0.01, 0.001, 0.004, 0.004, 0.01, 0.004, 0.001, 0.004,\n",
       "                    0.004, 0.004, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'sqrt', 'sqrt', 'auto', 'log2', 'sqrt', 'log2',\n",
       "                    'auto', 'log2', 'auto', 'sqrt', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'sqrt', 'auto', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'log2', 'log2', 'auto', 'auto', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'auto', 'sqrt', 'auto', 'auto',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'auto', 'sqrt', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'log2', 'auto', 'auto', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'auto', 'log2', 'sqrt', 'auto', 'log2',\n",
       "                    'auto', 'auto', 'log2', 'sqrt', 'auto', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'auto', 'log2', 'sqrt', 'auto',\n",
       "                    'auto', 'sqrt', 'auto', 'sqrt', 'auto', 'log2', 'auto',\n",
       "                    'sqrt', 'auto', 'log2', 'sqrt', 'sqrt', 'auto', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'log2', 'auto'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[20, 40, None, 50, None, 30, None, 10, 10, 30, 50, 10,\n",
       "                    None, 10, 50, None, 40, 20, 10, 30, 30, 20, 20, 40, 50,\n",
       "                    30, 30, 40, 10, None, None, 30, None, 50, 10, 10, 50,\n",
       "                    None, 20, 40, 40, None, 10, 40, None, 30, 10, None, 10,\n",
       "                    30, 10, 40, 40, 20, 50, 40, 10, 20, 40, 50, 50, 20, 40,\n",
       "                    50, None, 50, 20, 20, 10, 50, 10, 50, None, 20, 50, 50,\n",
       "                    40, 20, 50, 50, 30, 40, 10, 30, 20, 40, 20, 10, 30, 40,\n",
       "                    40, 50, 50, 10, 40, 10, None, 20, 20, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_bootstrap': masked_array(data=[True, True, False, True, False, False, False, False,\n",
       "                    False, True, True, False, True, True, True, True, True,\n",
       "                    True, False, True, True, True, True, True, False, True,\n",
       "                    False, True, True, False, True, True, True, True, True,\n",
       "                    True, False, False, False, True, True, True, False,\n",
       "                    True, False, False, False, False, True, True, True,\n",
       "                    False, True, False, False, True, True, False, False,\n",
       "                    False, True, True, True, False, True, True, False,\n",
       "                    False, True, False, True, False, True, True, False,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    True, False, True, True, False, False, False, False,\n",
       "                    False, False, False, False, False, True, False, True,\n",
       "                    False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.01,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 40,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 0.15,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 10,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': None,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.004,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': False},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 20,\n",
       "   'bootstrap': True},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 0.05,\n",
       "   'min_samples_leaf': 0.001,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 50,\n",
       "   'bootstrap': False}],\n",
       " 'split0_test_score': array([0.9685899 , 0.9363073 , 0.96911564, 0.93881295, 0.98578268,\n",
       "        0.95633012, 0.96686727, 0.97430591, 0.97626345, 0.96841093,\n",
       "        0.96735945, 0.98357905, 0.96672185, 0.93672118, 0.93273899,\n",
       "        0.963422  , 0.93326473, 0.96725878, 0.97124097, 0.98161033,\n",
       "        0.97536858, 0.98256113, 0.9804358 , 0.96683371, 0.98241571,\n",
       "        0.96659881, 0.9815544 , 0.97630819, 0.94015526, 0.9765431 ,\n",
       "        0.97464149, 0.96542428, 0.9618336 , 0.93341014, 0.97740442,\n",
       "        0.9764648 , 0.96473075, 0.97739323, 0.98518983, 0.97692342,\n",
       "        0.96792993, 0.96848923, 0.9671581 , 0.9765431 , 0.98392581,\n",
       "        0.968355  , 0.96728115, 0.98599521, 0.96748249, 0.96637509,\n",
       "        0.97750509, 0.98386989, 0.96812009, 0.98218081, 0.98648739,\n",
       "        0.96744894, 0.96506633, 0.96647576, 0.9833777 , 0.97286293,\n",
       "        0.94000984, 0.96601714, 0.97553637, 0.98274011, 0.98238216,\n",
       "        0.93627374, 0.97464149, 0.97754983, 0.93165395, 0.9693841 ,\n",
       "        0.96102821, 0.96964138, 0.95150898, 0.93632967, 0.96873532,\n",
       "        0.97483165, 0.98003311, 0.96555851, 0.9365422 , 0.98524575,\n",
       "        0.95756057, 0.96465245, 0.96023401, 0.96650932, 0.96954071,\n",
       "        0.98363498, 0.93810824, 0.9758272 , 0.96320947, 0.97809794,\n",
       "        0.98324347, 0.9837021 , 0.97748272, 0.98215844, 0.97633057,\n",
       "        0.96791875, 0.97514486, 0.98336652, 0.96781807, 0.98598403]),\n",
       " 'split1_test_score': array([0.96482024, 0.93643035, 0.96671066, 0.937974  , 0.98543592,\n",
       "        0.95853375, 0.96234815, 0.97485402, 0.97898163, 0.96762791,\n",
       "        0.96045773, 0.98211369, 0.96949596, 0.93613951, 0.93143023,\n",
       "        0.96411553, 0.93059129, 0.95873509, 0.96979798, 0.98251639,\n",
       "        0.97621871, 0.98287434, 0.98331059, 0.96681134, 0.98400412,\n",
       "        0.97069286, 0.98272892, 0.97621871, 0.93636323, 0.97537976,\n",
       "        0.97521197, 0.96587172, 0.9650887 , 0.9324146 , 0.97608448,\n",
       "        0.97672207, 0.95866798, 0.97999955, 0.98534643, 0.97744916,\n",
       "        0.97014475, 0.96427213, 0.97071523, 0.97468623, 0.98230385,\n",
       "        0.96824314, 0.96718047, 0.98551422, 0.96850041, 0.96933936,\n",
       "        0.97489877, 0.98327703, 0.96790756, 0.98347838, 0.98634198,\n",
       "        0.96881362, 0.96141972, 0.96583816, 0.98336652, 0.97493233,\n",
       "        0.94565874, 0.96720285, 0.97614041, 0.98244927, 0.98125238,\n",
       "        0.93556903, 0.97535739, 0.9766214 , 0.93200072, 0.96701268,\n",
       "        0.96693438, 0.96775096, 0.9573033 , 0.9371798 , 0.96466364,\n",
       "        0.97676682, 0.97996599, 0.966129  , 0.93782859, 0.98596165,\n",
       "        0.96751605, 0.96441755, 0.9596859 , 0.96439518, 0.97154299,\n",
       "        0.9810734 , 0.93553547, 0.97595024, 0.96310879, 0.97804201,\n",
       "        0.98303094, 0.98235978, 0.97639768, 0.98286315, 0.97836641,\n",
       "        0.96473075, 0.97525672, 0.98318754, 0.96424976, 0.98595047]),\n",
       " 'split2_test_score': array([0.96844413, 0.9384655 , 0.96487578, 0.93770484, 0.98643131,\n",
       "        0.9689475 , 0.96676622, 0.97837735, 0.97820956, 0.96692283,\n",
       "        0.96876853, 0.98392564, 0.96876853, 0.9380628 , 0.93021019,\n",
       "        0.96648657, 0.927794  , 0.96767229, 0.97232569, 0.98248263,\n",
       "        0.97747128, 0.98348938, 0.98174435, 0.96674385, 0.98433952,\n",
       "        0.96979764, 0.98320973, 0.97744891, 0.93883464, 0.97672181,\n",
       "        0.97666588, 0.96856718, 0.96370124, 0.93306263, 0.97789635,\n",
       "        0.97820956, 0.96409275, 0.97871293, 0.98602861, 0.97701265,\n",
       "        0.97091625, 0.96891395, 0.96544627, 0.97667707, 0.98473103,\n",
       "        0.96771704, 0.96531204, 0.98633064, 0.97014441, 0.96784008,\n",
       "        0.97694554, 0.98370191, 0.96836583, 0.98437308, 0.98627471,\n",
       "        0.96827634, 0.96949562, 0.96714655, 0.98361243, 0.9761737 ,\n",
       "        0.950099  , 0.96599438, 0.97716926, 0.98448494, 0.98165487,\n",
       "        0.93786145, 0.97677774, 0.97766144, 0.9303556 , 0.96996544,\n",
       "        0.96844413, 0.95743705, 0.95564728, 0.94015459, 0.96895869,\n",
       "        0.97752721, 0.98158775, 0.96671029, 0.93795094, 0.98663266,\n",
       "        0.96433885, 0.96853362, 0.95847735, 0.96573711, 0.97284025,\n",
       "        0.98301956, 0.9409488 , 0.97714688, 0.96817567, 0.97923868,\n",
       "        0.98278466, 0.98450731, 0.97716926, 0.98304194, 0.97901496,\n",
       "        0.96989832, 0.97703502, 0.98399275, 0.96701232, 0.98666622]),\n",
       " 'mean_test_score': array([0.96728475, 0.93706771, 0.9669007 , 0.93816393, 0.9858833 ,\n",
       "        0.96127043, 0.96532721, 0.97584575, 0.97781821, 0.96765389,\n",
       "        0.96552856, 0.98320612, 0.96832878, 0.93697449, 0.93145981,\n",
       "        0.96467469, 0.93055001, 0.96455538, 0.97112154, 0.98220311,\n",
       "        0.97635285, 0.98297495, 0.98183025, 0.9667963 , 0.98358645,\n",
       "        0.96902977, 0.98249768, 0.9766586 , 0.93845104, 0.97621489,\n",
       "        0.97550644, 0.96662105, 0.96354118, 0.93296246, 0.97712841,\n",
       "        0.97713214, 0.96249716, 0.9787019 , 0.98552162, 0.97712841,\n",
       "        0.96966364, 0.9672251 , 0.96777321, 0.9759688 , 0.98365356,\n",
       "        0.96810506, 0.96659122, 0.98594669, 0.9687091 , 0.96785151,\n",
       "        0.9764498 , 0.98361628, 0.96813116, 0.98334408, 0.98636803,\n",
       "        0.96817963, 0.96532721, 0.96648682, 0.98345222, 0.97465631,\n",
       "        0.94525584, 0.96640479, 0.97628201, 0.98322477, 0.98176313,\n",
       "        0.93656807, 0.9755922 , 0.97727756, 0.93133676, 0.9687874 ,\n",
       "        0.9654689 , 0.96494316, 0.95481985, 0.93788801, 0.96745254,\n",
       "        0.97637522, 0.98052895, 0.9661326 , 0.93744057, 0.98594669,\n",
       "        0.96313849, 0.96586786, 0.95946576, 0.9655472 , 0.97130798,\n",
       "        0.98257598, 0.93819749, 0.97630811, 0.9648313 , 0.97845954,\n",
       "        0.98301969, 0.98352306, 0.97701655, 0.98268784, 0.97790397,\n",
       "        0.96751593, 0.97581219, 0.9835156 , 0.96636005, 0.98620024]),\n",
       " 'std_test_score': array([1.74369371e-03, 9.89655469e-04, 1.73612279e-03, 4.71895765e-04,\n",
       "        4.12550112e-04, 5.50252188e-03, 2.10692147e-03, 1.80403116e-03,\n",
       "        1.14367756e-03, 6.07791011e-04, 3.63147825e-03, 7.85318524e-04,\n",
       "        1.17443976e-03, 8.05349967e-04, 1.03258967e-03, 1.31209611e-03,\n",
       "        2.23360425e-03, 4.11903291e-03, 1.03538227e-03, 4.19392078e-04,\n",
       "        8.63648883e-04, 3.85575209e-04, 1.17519867e-03, 3.81950484e-05,\n",
       "        8.39083392e-04, 1.75737543e-03, 6.95285476e-04, 5.60021454e-04,\n",
       "        1.57167563e-03, 5.95016094e-04, 8.52281297e-04, 1.38818123e-03,\n",
       "        1.33370507e-03, 4.12557880e-04, 7.65007420e-04, 7.69052668e-04,\n",
       "        2.72014386e-03, 1.06405717e-03, 3.64152586e-04, 2.29711018e-04,\n",
       "        1.26573311e-03, 2.09525337e-03, 2.19457546e-03, 9.08559926e-04,\n",
       "        1.00941731e-03, 2.78145293e-04, 9.05451010e-04, 3.35063342e-04,\n",
       "        1.09669551e-03, 1.21018825e-03, 1.12028316e-03, 2.49492428e-04,\n",
       "        1.87251113e-04, 9.00012437e-04, 8.87610323e-05, 5.61311865e-04,\n",
       "        3.30212666e-03, 5.34203360e-04, 1.13377014e-04, 1.36563338e-03,\n",
       "        4.12871652e-03, 5.64388206e-04, 6.74101792e-04, 8.98945904e-04,\n",
       "        4.67541654e-04, 9.58737903e-04, 8.87785923e-04, 4.66206058e-04,\n",
       "        7.08074528e-04, 1.27716316e-03, 3.19996757e-03, 5.36340546e-03,\n",
       "        2.43680440e-03, 1.63985152e-03, 1.97416607e-03, 1.13475883e-03,\n",
       "        7.49182814e-04, 4.70218138e-04, 6.37206041e-04, 5.66300423e-04,\n",
       "        4.15199770e-03, 1.88740144e-03, 7.33850725e-04, 8.73479787e-04,\n",
       "        1.35724462e-03, 1.09178768e-03, 2.21088205e-03, 5.95225505e-04,\n",
       "        2.36516989e-03, 5.51401320e-04, 1.87479416e-04, 8.85816088e-04,\n",
       "        4.55935258e-04, 3.81394627e-04, 1.14363975e-03, 2.12878882e-03,\n",
       "        8.65870632e-04, 3.45214334e-04, 1.52802991e-03, 3.29782461e-04]),\n",
       " 'rank_test_score': array([ 62,  94,  64,  91,   5,  85,  76,  42,  28,  59,  74,  15,  53,\n",
       "         95,  98,  80, 100,  81,  48,  21,  37,  17,  22,  65,   9,  50,\n",
       "         20,  34,  89,  40,  45,  66,  82,  97,  31,  30,  84,  25,   6,\n",
       "         31,  49,  63,  58,  41,   7,  56,  67,   3,  52,  57,  35,   8,\n",
       "         55,  13,   1,  54,  76,  68,  12,  46,  88,  69,  39,  14,  23,\n",
       "         96,  44,  29,  99,  51,  75,  78,  87,  92,  61,  36,  24,  71,\n",
       "         93,   3,  83,  72,  86,  73,  47,  19,  90,  38,  79,  26,  16,\n",
       "         10,  33,  18,  27,  60,  43,  11,  70,   2], dtype=int32),\n",
       " 'split0_train_score': array([0.96933359, 0.9366649 , 0.96990967, 0.93912022, 0.98624682,\n",
       "        0.95708493, 0.96791297, 0.97525658, 0.97705193, 0.96933919,\n",
       "        0.96833245, 0.98385861, 0.96764451, 0.93703963, 0.9329064 ,\n",
       "        0.9642999 , 0.93349926, 0.9684499 , 0.97200145, 0.9824268 ,\n",
       "        0.97608434, 0.98305881, 0.98121312, 0.96758299, 0.98317067,\n",
       "        0.96734808, 0.98245477, 0.97710227, 0.94094913, 0.97742107,\n",
       "        0.97538522, 0.96650913, 0.96258285, 0.93376213, 0.9783551 ,\n",
       "        0.97728684, 0.96567018, 0.97855085, 0.98552532, 0.97762242,\n",
       "        0.96893649, 0.96932241, 0.96816466, 0.97728124, 0.98436198,\n",
       "        0.96947901, 0.96847227, 0.98616852, 0.96823177, 0.96712436,\n",
       "        0.97824324, 0.98440672, 0.96919377, 0.98293017, 0.98661036,\n",
       "        0.96830448, 0.96606169, 0.96760536, 0.98376912, 0.97352275,\n",
       "        0.94120641, 0.96699572, 0.97649263, 0.98326575, 0.98303644,\n",
       "        0.93663134, 0.97565368, 0.97828798, 0.93155849, 0.97016136,\n",
       "        0.96187813, 0.97083811, 0.95244274, 0.93667049, 0.96940071,\n",
       "        0.97582706, 0.98088313, 0.96654828, 0.93693336, 0.98577141,\n",
       "        0.95856707, 0.9658156 , 0.96083783, 0.96748791, 0.97050812,\n",
       "        0.98392013, 0.9387343 , 0.97681703, 0.96436701, 0.97884728,\n",
       "        0.98357337, 0.984183  , 0.97841103, 0.98284068, 0.97724209,\n",
       "        0.96897005, 0.97597248, 0.9836237 , 0.96899801, 0.98640902]),\n",
       " 'split1_train_score': array([0.96547443, 0.93780587, 0.96742079, 0.93924886, 0.98595039,\n",
       "        0.95939484, 0.96289605, 0.97532929, 0.9796359 , 0.96792975,\n",
       "        0.9611846 , 0.98229257, 0.96966358, 0.93752062, 0.93287284,\n",
       "        0.96466344, 0.93206186, 0.9595067 , 0.97035152, 0.98287424,\n",
       "        0.97687855, 0.98341117, 0.98385861, 0.96772281, 0.98452977,\n",
       "        0.97134707, 0.9833888 , 0.97697363, 0.9377779 , 0.97601723,\n",
       "        0.97601723, 0.9665315 , 0.96561425, 0.93376213, 0.97670517,\n",
       "        0.97737073, 0.95933331, 0.98041332, 0.98603429, 0.97809223,\n",
       "        0.97032915, 0.96499902, 0.97125199, 0.97519506, 0.9827456 ,\n",
       "        0.96905394, 0.9680472 , 0.98614055, 0.96915462, 0.96969155,\n",
       "        0.97544115, 0.98377471, 0.96829889, 0.98408233, 0.98696832,\n",
       "        0.96927766, 0.96191169, 0.96641405, 0.98374675, 0.97568165,\n",
       "        0.94639671, 0.96780671, 0.97681703, 0.98303644, 0.98180598,\n",
       "        0.93702844, 0.97579351, 0.97706312, 0.9336279 , 0.9678123 ,\n",
       "        0.96752146, 0.96851142, 0.95795744, 0.93838754, 0.96553036,\n",
       "        0.97737632, 0.98071534, 0.96697335, 0.93926564, 0.98662155,\n",
       "        0.96831008, 0.9651724 , 0.96032887, 0.96481445, 0.97186722,\n",
       "        0.9813865 , 0.93699488, 0.97669957, 0.96356162, 0.97863475,\n",
       "        0.98350625, 0.98293017, 0.97727006, 0.98347269, 0.97897592,\n",
       "        0.96546324, 0.97585503, 0.98360133, 0.96502699, 0.98646495]),\n",
       " 'split2_train_score': array([0.96737623, 0.93665406, 0.96405401, 0.93592698, 0.98586657,\n",
       "        0.96768384, 0.96560326, 0.97745475, 0.97727578, 0.96597239,\n",
       "        0.9674769 , 0.98310924, 0.96784044, 0.93634086, 0.92904763,\n",
       "        0.96541869, 0.92654757, 0.96633594, 0.97102843, 0.98159355,\n",
       "        0.97641446, 0.98267858, 0.98085528, 0.96556411, 0.98388107,\n",
       "        0.96840533, 0.98264503, 0.97629142, 0.93687219, 0.97581601,\n",
       "        0.97551959, 0.96739301, 0.96264458, 0.93154209, 0.9768619 ,\n",
       "        0.97706325, 0.96315913, 0.9778183 , 0.98548066, 0.97586635,\n",
       "        0.9696246 , 0.96786841, 0.96442873, 0.97564263, 0.98397056,\n",
       "        0.96671066, 0.96420502, 0.98567082, 0.96883599, 0.96672744,\n",
       "        0.97599499, 0.98286315, 0.96726996, 0.98383073, 0.98565963,\n",
       "        0.96720844, 0.96801942, 0.96607307, 0.98309806, 0.97503859,\n",
       "        0.94812524, 0.96487058, 0.97610685, 0.98373006, 0.98100069,\n",
       "        0.93608917, 0.97568178, 0.9766997 , 0.92893018, 0.96861787,\n",
       "        0.96716929, 0.95602251, 0.95474172, 0.93846059, 0.96758317,\n",
       "        0.97651513, 0.98079935, 0.96542428, 0.93632967, 0.98603996,\n",
       "        0.96309761, 0.96718047, 0.95749905, 0.96498244, 0.97149265,\n",
       "        0.98225352, 0.9388521 , 0.97618515, 0.9669176 , 0.97833285,\n",
       "        0.98198506, 0.98373006, 0.97642565, 0.98233182, 0.97799727,\n",
       "        0.96852279, 0.9759838 , 0.98333855, 0.96575986, 0.98609589]),\n",
       " 'mean_train_score': array([0.96739475, 0.93704161, 0.96712816, 0.93809869, 0.98602126,\n",
       "        0.96138787, 0.96547076, 0.97601354, 0.97798787, 0.96774711,\n",
       "        0.96566465, 0.98308681, 0.96838284, 0.93696704, 0.93160896,\n",
       "        0.96479401, 0.9307029 , 0.96476418, 0.97112714, 0.9822982 ,\n",
       "        0.97645912, 0.98304952, 0.98197567, 0.96695663, 0.9838605 ,\n",
       "        0.9690335 , 0.98282953, 0.9767891 , 0.93853307, 0.9764181 ,\n",
       "        0.97564068, 0.96681121, 0.96361389, 0.93302212, 0.97730739,\n",
       "        0.97724027, 0.96272088, 0.97892749, 0.98568009, 0.97719367,\n",
       "        0.96963008, 0.96739661, 0.96794846, 0.97603964, 0.98369271,\n",
       "        0.96841454, 0.96690816, 0.9859933 , 0.96874079, 0.96784778,\n",
       "        0.97655979, 0.98368153, 0.96825421, 0.98361441, 0.98641277,\n",
       "        0.96826353, 0.96533093, 0.96669749, 0.98353798, 0.97474766,\n",
       "        0.94524279, 0.96655767, 0.97647217, 0.98334408, 0.9819477 ,\n",
       "        0.93658298, 0.97570966, 0.97735027, 0.93137219, 0.96886384,\n",
       "        0.96552296, 0.96512401, 0.9550473 , 0.93783954, 0.96750474,\n",
       "        0.97657284, 0.98079928, 0.9663153 , 0.93750956, 0.98614431,\n",
       "        0.96332492, 0.96605616, 0.95955525, 0.9657616 , 0.97128933,\n",
       "        0.98252005, 0.93819376, 0.97656725, 0.96494875, 0.97860496,\n",
       "        0.98302156, 0.98361441, 0.97736891, 0.98288173, 0.97807176,\n",
       "        0.96765203, 0.9759371 , 0.9835212 , 0.96659495, 0.98632328]),\n",
       " 'std_train_score': array([1.57555330e-03, 5.40430273e-04, 2.39950493e-03, 1.53652753e-03,\n",
       "        1.63122749e-04, 4.55070404e-03, 2.05029022e-03, 1.01952376e-03,\n",
       "        1.16890919e-03, 1.38054196e-03, 3.18707153e-03, 6.39529662e-04,\n",
       "        9.09143212e-04, 4.84365032e-04, 1.81118444e-03, 4.65983087e-04,\n",
       "        2.99628257e-03, 3.81645887e-03, 6.77188939e-04, 5.30690318e-04,\n",
       "        3.25767071e-04, 2.99149025e-04, 1.33943046e-03, 9.86319223e-04,\n",
       "        5.55040176e-04, 1.69192743e-03, 4.03017485e-04, 3.55815766e-04,\n",
       "        1.74796611e-03, 7.13945350e-04, 2.71852790e-04, 4.11491380e-04,\n",
       "        1.41469202e-03, 1.04653555e-03, 7.43602158e-04, 1.29777405e-04,\n",
       "        2.60550947e-03, 1.09237733e-03, 2.51117309e-04, 9.57950644e-04,\n",
       "        5.68562796e-04, 1.79626698e-03, 2.78977518e-03, 8.96756782e-04,\n",
       "        6.88508822e-04, 1.21725517e-03, 1.91927596e-03, 2.28310659e-04,\n",
       "        3.82716094e-04, 1.31376856e-03, 1.21166046e-03, 6.33595964e-04,\n",
       "        7.86026645e-04, 4.94613257e-04, 5.52234092e-04, 8.45254076e-04,\n",
       "        2.54644909e-03, 6.56878380e-04, 3.11204082e-04, 9.05055751e-04,\n",
       "        2.94009105e-03, 1.23804372e-03, 2.90289416e-04, 2.88536621e-04,\n",
       "        8.37109587e-04, 3.84975120e-04, 6.03903216e-05, 6.79460937e-04,\n",
       "        1.92235539e-03, 9.74644295e-04, 2.58129208e-03, 6.50545647e-03,\n",
       "        2.26171057e-03, 8.27181866e-04, 1.58103832e-03, 6.33797781e-04,\n",
       "        6.84999696e-05, 6.53508912e-04, 1.26595921e-03, 3.54823363e-04,\n",
       "        3.98081010e-03, 8.37252583e-04, 1.46872519e-03, 1.22260807e-03,\n",
       "        5.73173006e-04, 1.05137929e-03, 8.49098940e-04, 2.74406930e-04,\n",
       "        1.43049333e-03, 2.11070719e-04, 7.33429381e-04, 5.17962502e-04,\n",
       "        8.13537431e-04, 4.66662862e-04, 7.09789957e-04, 1.55843859e-03,\n",
       "        5.82197933e-05, 1.29470275e-04, 1.72536025e-03, 1.62406882e-04])}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340968"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
